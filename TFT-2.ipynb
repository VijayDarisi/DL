{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1daceb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"final-modified.csv\")  # change path as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0484cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix data types for categoricals\n",
    "df[\"PLATFORM\"] = df[\"PLATFORM\"].astype(str)\n",
    "df[\"PRACTICE\"] = df[\"PRACTICE\"].astype(str)\n",
    "df[\"HORIZON\"] = df[\"HORIZON\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6439f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add ID and time_idx\n",
    "df[\"ID\"] = df[\"PLATFORM\"].astype(str) + \"_\" + df[\"PRACTICE\"].astype(str) + \"_\" + df[\"HORIZON\"].astype(str)\n",
    "df[\"YEAR-MONTH\"] = pd.to_datetime(df[\"YEAR-MONTH\"])\n",
    "df = df.sort_values(by=[\"ID\", \"YEAR-MONTH\"])\n",
    "df[\"time_idx\"] = df.groupby(\"ID\")[\"YEAR-MONTH\"].rank(method=\"dense\").astype(int) - 1\n",
    "\n",
    "# Split based on TRAIN/TEST column\n",
    "train_df = df[df[\"TRAIN/TEST\"] == \"TRAIN\"]\n",
    "val_df = df[df[\"TRAIN/TEST\"] == \"VALIDATION\"]\n",
    "test_df = df[df[\"TRAIN/TEST\"] == \"TEST\"]\n",
    "\n",
    "# Set up model parameters\n",
    "max_encoder_length = 5\n",
    "max_prediction_length = 1  # Monthly data, 1-step ahead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cf5cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify features\n",
    "static_categoricals = [\"PLATFORM\", \"PRACTICE\", \"HORIZON\"]\n",
    "known_reals = [\"time_idx\"] + [col for col in df.columns if \"__regressor\" in col or \"Expected_Inflation\" in col]\n",
    "unknown_reals = [\"ACTUAL\"]\n",
    "\n",
    "# Create training dataset\n",
    "training = TimeSeriesDataSet(\n",
    "    train_df,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"ACTUAL\",\n",
    "    group_ids=[\"ID\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=static_categoricals,\n",
    "    time_varying_known_reals=known_reals,\n",
    "    time_varying_unknown_reals=unknown_reals,\n",
    "    target_normalizer=GroupNormalizer(groups=[\"ID\"]),\n",
    ")\n",
    "\n",
    "# Create validation and test datasets\n",
    "validation = training.from_parameters(training.get_parameters(), val_df)\n",
    "test = training.from_parameters(training.get_parameters(), test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de94630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dataloaders\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=8, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=8, num_workers=0)\n",
    "test_dataloader = test.to_dataloader(train=False, batch_size=8, num_workers=0)\n",
    "\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,\n",
    "    log_val_interval=1,\n",
    ")\n",
    "\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=5)],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82ddd4b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `TemporalFusionTransformer`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bdarisi001\\Desktop\\PwC working\\Testing DL\\dlmodels\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:538\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\n\u001b[32m    505\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    506\u001b[39m     model: \u001b[33m\"\u001b[39m\u001b[33mpl.LightningModule\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    510\u001b[39m     ckpt_path: Optional[_PATH] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    511\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    512\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Runs the full optimization routine.\u001b[39;00m\n\u001b[32m    513\u001b[39m \n\u001b[32m    514\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    536\u001b[39m \n\u001b[32m    537\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m538\u001b[39m     model = \u001b[43m_maybe_unwrap_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    539\u001b[39m     \u001b[38;5;28mself\u001b[39m.strategy._lightning_module = model\n\u001b[32m    540\u001b[39m     _verify_strategy_supports_compile(model, \u001b[38;5;28mself\u001b[39m.strategy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bdarisi001\\Desktop\\PwC working\\Testing DL\\dlmodels\\Lib\\site-packages\\pytorch_lightning\\utilities\\compile.py:132\u001b[39m, in \u001b[36m_maybe_unwrap_optimized\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m    131\u001b[39m _check_mixed_imports(model)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    133\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model).\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: `model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `TemporalFusionTransformer`"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.fit(tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4637af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "predictions = tft.predict(test_dataloader, return_y=True)\n",
    "y_pred = predictions[0].numpy()\n",
    "y_true = predictions[1].numpy()\n",
    "\n",
    "# Evaluation metrics\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "print(\"Test Results:\")\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "print(\"MAE:\", mean_absolute_error(y_true, y_pred))\n",
    "print(\"R2:\", r2_score(y_true, y_pred))\n",
    "print(\"MAPE:\", calculate_mape(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95305169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed0f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4abee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
